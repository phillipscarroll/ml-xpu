{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7mWFNse-pzE"
      },
      "source": [
        "# Train And Test - Regression XPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcLiQBnz-pzH"
      },
      "source": [
        "## Linear Regression\n",
        "\n",
        "- Imports\n",
        "  - standard libs\n",
        "  - 3rd party libs\n",
        "  - alpabetical or logical grouping\n",
        "- Set random seed\n",
        "- Config and Hyperparams\n",
        "- Dataset and Dataloader\n",
        "- Model definition/class\n",
        "- Helper functions (training, eval, visualization)\n",
        "- Then main code\n",
        "\n",
        "Note: You can flip torch.amp on and off to test on XPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.amp import GradScaler, autocast\n",
        "\n",
        "\n",
        "# Set for reproducibility or turn on RANDOMIZE_SEED to randomize it\n",
        "RANDOM_SEED = 42\n",
        "RANDOMIZE_SEED = False\n",
        "\n",
        "if RANDOMIZE_SEED:\n",
        "    RANDOM_SEED = random.randint(0, 1000000000)\n",
        "    print(f\"Using seed: {RANDOM_SEED}\")\n",
        "\n",
        "device = \"xpu\" if torch.xpu.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize Hyperparameters\n",
        "# Use step to increase or decrease the dataset size, lower number = more data, higher number = less data\n",
        "start, end, step, weight, bias = 0, 1, 0.0002, 0.7, 0.3\n",
        "learning_rate = 0.001\n",
        "epochs = 1500\n",
        "\n",
        "# Set to True to use mixed precision training (automatic mixed precision)\n",
        "use_amp = True\n",
        "\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear_layer = nn.Linear(in_features=1, \n",
        "                                      out_features=1)\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.linear_layer(x)\n",
        "\n",
        "# Generate dataset and return the training and test data\n",
        "def generate_dataset(start=0, end=1, step=0.0002, weight=0.7, bias=0.3):\n",
        "    \"\"\"\n",
        "    Generate a dataset for a sample linear regression problem.\n",
        "\n",
        "    Args:\n",
        "        start (float): The start of the X values.\n",
        "        end (float): The end of the X values.\n",
        "        step (float): The step between X values.\n",
        "        weight (float): The weight of the linear equation.\n",
        "        bias (float): The bias of the linear equation.\n",
        "\n",
        "    Returns:\n",
        "        tuple: X_train, y_train, X_test, y_test\n",
        "    \"\"\"\n",
        "    \n",
        "    X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "    y = weight * X + bias \n",
        "    X[:10], y[:10]\n",
        "    \n",
        "    train_split = int(0.8 * len(X))\n",
        "    X_train, y_train = X[:train_split], y[:train_split]\n",
        "    X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "# Plotting function to visualize the data\n",
        "def plot_predictions(train_data, train_labels, test_data, test_labels, predictions=None):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "  \n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "\n",
        "  if predictions is not None:\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  plt.legend(prop={\"size\": 14});\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"\n",
        "    Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    torch.xpu.manual_seed(seed)\n",
        "\n",
        "def move_to_device(x, y, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Moves data to the target device.\n",
        "    \"\"\"\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    X_test = X_test.to(device)\n",
        "    y_test = y_test.to(device)\n",
        "    print(f\"X_train device: {x.device}, y_train device: {y.device}\")\n",
        "    print(f\"X_test device: {X_test.device}, y_test device: {y_test.device}\")\n",
        "    return x, y, X_test, y_test\n",
        "\n",
        "\n",
        "X_train, y_train, X_test, y_test = generate_dataset(start, end, step, weight, bias)\n",
        "\n",
        "plot_predictions(X_train.cpu(), y_train.cpu(), X_test.cpu(), y_test.cpu())\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
        "\n",
        "set_seed(RANDOM_SEED)\n",
        "\n",
        "# This should instantiate the model and move it to the GPU\n",
        "model_0 = LinearRegressionModel()\n",
        "model_0.to(device)\n",
        "\n",
        "loss_fn = nn.L1Loss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=learning_rate)\n",
        "\n",
        "set_seed(RANDOM_SEED)\n",
        "\n",
        "X_train, y_train, X_test, y_test = move_to_device(X_train, y_train, X_test, y_test)\n",
        "\n",
        "if use_amp:\n",
        "    scaler = torch.amp.GradScaler(device)\n",
        "\n",
        "# Train and Test loop\n",
        "for epoch in range(epochs):\n",
        "    model_0.train()\n",
        "\n",
        "    if use_amp:\n",
        "        with torch.amp.autocast(device):\n",
        "            y_pred = model_0(X_train)\n",
        "            loss = loss_fn(y_pred, y_train)\n",
        "            optimizer.zero_grad()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "    else:\n",
        "        y_pred = model_0(X_train)\n",
        "        loss = loss_fn(y_pred, y_train)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    model_0.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        if use_amp:\n",
        "            with torch.amp.autocast(device):\n",
        "                test_pred = model_0(X_test)\n",
        "        else:\n",
        "            test_pred = model_0(X_test)\n",
        "    \n",
        "        test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch: {epoch} | Train loss: {loss} | Test loss: {test_loss}\")\n",
        "\n",
        "# Turn on evaluation mode so we don't update the model weights\n",
        "model_0.eval()\n",
        "\n",
        "# Make predictions on the test data\n",
        "with torch.inference_mode():\n",
        "    y_preds = model_0(X_test)\n",
        "\n",
        "plot_predictions(X_train.cpu(), y_train.cpu(), X_test.cpu(), y_test.cpu(), y_preds.cpu())\n",
        "\n",
        "# Create models directory if it doesn't exist\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Create model save path if it doesn't exist\n",
        "MODEL_NAME = \"LinearRegressionModel_model_0.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# 3. Save the model state dict \n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_0.state_dict(), f=MODEL_SAVE_PATH) \n",
        "\n",
        "# Load the newly saved model\n",
        "loaded_model_0 = LinearRegressionModel()\n",
        "loaded_model_0.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "loaded_model_0.to(device)\n",
        "\n",
        "# Evaluate loaded model\n",
        "loaded_model_0.eval()\n",
        "with torch.inference_mode():\n",
        "    loaded_model_0_preds = loaded_model_0(X_test)\n",
        "y_preds == loaded_model_0_preds"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
