{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7mWFNse-pzE"
      },
      "source": [
        "# Train And Test - Classification XPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcLiQBnz-pzH"
      },
      "source": [
        "## Classification\n",
        "\n",
        "- Imports\n",
        "  - standard libs\n",
        "  - 3rd party libs\n",
        "  - alpabetical or logical grouping\n",
        "- Set random seed\n",
        "- Config and Hyperparams\n",
        "- Dataset and Dataloader\n",
        "- Model definition/class\n",
        "- Helper functions (training, eval, visualization)\n",
        "- Then main code\n",
        "\n",
        "Note: You can flip torch.amp on and off to test, this is work on XPU. Note this is not a great example case for leveraging amp but it is functional for testing. This is a setting with the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-02 22:37:40,371 - root - INFO - Seed set to: 817593105\n",
            "2025-02-02 22:37:40,372 - root - INFO - Using device: cuda\n",
            "2025-02-02 22:37:40,397 - root - INFO - Seed has been set: 817593105\n",
            "2025-02-02 22:37:40,458 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /distilbert/distilgpt2/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
            "2025-02-02 22:37:40,459 - filelock - DEBUG - Attempting to acquire lock 1345733461440 on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\be4d21d94f3b4687e5a54d84bf6ab46ed0f8defd.lock\n",
            "2025-02-02 22:37:40,460 - filelock - DEBUG - Lock 1345733461440 acquired on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\be4d21d94f3b4687e5a54d84bf6ab46ed0f8defd.lock\n",
            "2025-02-02 22:37:40,517 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"GET /distilbert/distilgpt2/resolve/main/tokenizer_config.json HTTP/1.1\" 200 26\n",
            "2025-02-02 22:37:40,520 - filelock - DEBUG - Attempting to release lock 1345733461440 on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\be4d21d94f3b4687e5a54d84bf6ab46ed0f8defd.lock\n",
            "2025-02-02 22:37:40,521 - filelock - DEBUG - Lock 1345733461440 released on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\be4d21d94f3b4687e5a54d84bf6ab46ed0f8defd.lock\n",
            "2025-02-02 22:37:40,586 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /distilbert/distilgpt2/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "2025-02-02 22:37:40,588 - filelock - DEBUG - Attempting to acquire lock 1345728555504 on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\fed02aafb76b46aa5da200966f9e42262e758023.lock\n",
            "2025-02-02 22:37:40,588 - filelock - DEBUG - Lock 1345728555504 acquired on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\fed02aafb76b46aa5da200966f9e42262e758023.lock\n",
            "2025-02-02 22:37:40,662 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"GET /distilbert/distilgpt2/resolve/main/config.json HTTP/1.1\" 200 762\n",
            "2025-02-02 22:37:40,664 - filelock - DEBUG - Attempting to release lock 1345728555504 on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\fed02aafb76b46aa5da200966f9e42262e758023.lock\n",
            "2025-02-02 22:37:40,664 - filelock - DEBUG - Lock 1345728555504 released on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\fed02aafb76b46aa5da200966f9e42262e758023.lock\n",
            "2025-02-02 22:37:40,726 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /distilbert/distilgpt2/resolve/main/vocab.json HTTP/1.1\" 200 0\n",
            "2025-02-02 22:37:40,727 - filelock - DEBUG - Attempting to acquire lock 1345743585408 on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\1f1d9aaca301414e7f6c9396df506798ff4eb9a6.lock\n",
            "2025-02-02 22:37:40,727 - filelock - DEBUG - Lock 1345743585408 acquired on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\1f1d9aaca301414e7f6c9396df506798ff4eb9a6.lock\n",
            "2025-02-02 22:37:40,801 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"GET /distilbert/distilgpt2/resolve/main/vocab.json HTTP/1.1\" 200 1042301\n",
            "2025-02-02 22:37:40,828 - filelock - DEBUG - Attempting to release lock 1345743585408 on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\1f1d9aaca301414e7f6c9396df506798ff4eb9a6.lock\n",
            "2025-02-02 22:37:40,828 - filelock - DEBUG - Lock 1345743585408 released on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\1f1d9aaca301414e7f6c9396df506798ff4eb9a6.lock\n",
            "2025-02-02 22:37:40,892 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /distilbert/distilgpt2/resolve/main/merges.txt HTTP/1.1\" 200 0\n",
            "2025-02-02 22:37:40,894 - filelock - DEBUG - Attempting to acquire lock 1345743585408 on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\226b0752cac7789c48f0cb3ec53eda48b7be36cc.lock\n",
            "2025-02-02 22:37:40,894 - filelock - DEBUG - Lock 1345743585408 acquired on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\226b0752cac7789c48f0cb3ec53eda48b7be36cc.lock\n",
            "2025-02-02 22:37:40,953 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"GET /distilbert/distilgpt2/resolve/main/merges.txt HTTP/1.1\" 200 456318\n",
            "2025-02-02 22:37:41,012 - filelock - DEBUG - Attempting to release lock 1345743585408 on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\226b0752cac7789c48f0cb3ec53eda48b7be36cc.lock\n",
            "2025-02-02 22:37:41,012 - filelock - DEBUG - Lock 1345743585408 released on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\226b0752cac7789c48f0cb3ec53eda48b7be36cc.lock\n",
            "2025-02-02 22:37:41,120 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /distilbert/distilgpt2/resolve/main/tokenizer.json HTTP/1.1\" 200 0\n",
            "2025-02-02 22:37:41,121 - filelock - DEBUG - Attempting to acquire lock 1345740641952 on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\4b988bccc9dc5adacd403c00b4704976196548f8.lock\n",
            "2025-02-02 22:37:41,122 - filelock - DEBUG - Lock 1345740641952 acquired on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\4b988bccc9dc5adacd403c00b4704976196548f8.lock\n",
            "2025-02-02 22:37:41,185 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"GET /distilbert/distilgpt2/resolve/main/tokenizer.json HTTP/1.1\" 200 1355256\n",
            "2025-02-02 22:37:41,308 - filelock - DEBUG - Attempting to release lock 1345740641952 on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\4b988bccc9dc5adacd403c00b4704976196548f8.lock\n",
            "2025-02-02 22:37:41,309 - filelock - DEBUG - Lock 1345740641952 released on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\4b988bccc9dc5adacd403c00b4704976196548f8.lock\n",
            "2025-02-02 22:37:41,380 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /distilbert/distilgpt2/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
            "2025-02-02 22:37:41,444 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /distilbert/distilgpt2/resolve/main/special_tokens_map.json HTTP/1.1\" 404 0\n",
            "2025-02-02 22:37:41,504 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /distilbert/distilgpt2/resolve/main/chat_template.jinja HTTP/1.1\" 404 0\n",
            "2025-02-02 22:37:41,710 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /distilbert/distilgpt2/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "2025-02-02 22:37:41,816 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /distilbert/distilgpt2/resolve/main/model.safetensors HTTP/1.1\" 302 0\n",
            "2025-02-02 22:37:41,817 - filelock - DEBUG - Attempting to acquire lock 1346538009616 on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\e1ff18884359fe8beb795a5f414feb85a6ce3d929ad019c0d958c039d2b94a1b.lock\n",
            "2025-02-02 22:37:41,818 - filelock - DEBUG - Lock 1346538009616 acquired on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\e1ff18884359fe8beb795a5f414feb85a6ce3d929ad019c0d958c039d2b94a1b.lock\n",
            "2025-02-02 22:37:41,835 - urllib3.connectionpool - DEBUG - https://cdn-lfs.hf.co:443 \"GET /distilgpt2/e1ff18884359fe8beb795a5f414feb85a6ce3d929ad019c0d958c039d2b94a1b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1738561252&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczODU2MTI1Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9kaXN0aWxncHQyL2UxZmYxODg4NDM1OWZlOGJlYjc5NWE1ZjQxNGZlYjg1YTZjZTNkOTI5YWQwMTljMGQ5NThjMDM5ZDJiOTRhMWI~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=RJhYEgTEr1dbhTjwi~Dkj2LS99Wl0AaZVCxmaNof00vD40vED5OdjvaZPdBusC~tqHpPO9KoxCgfm2Uu2-81VquXtGEKvZR8aFQ31P7VxaEpLIgDM3QJ7-uODrPYbaAfsZ2019XppXQwTkOR4m7IZ7FGMbCeKGPQqSR8-4TKf95R9O2LSkPZf~GxUn8xvoVKoQyeyGtXj80BkhMmJ9KCgh35PMWmnGy9wAetlDgDze12Q7Wfm-FDtMWEET~wSSs4VZQfIVvteaoHk7IOBZtE~E0Q61f86jKdu8h4DHuKFZMU0VuFtj0fFX77Q-qPCKTnPgoQQuyZ78RdhbwJnRd4nA__&Key-Pair-Id=K3RPWS32NSSJCE HTTP/1.1\" 200 352824413\n",
            "2025-02-02 22:37:45,270 - filelock - DEBUG - Attempting to release lock 1346538009616 on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\e1ff18884359fe8beb795a5f414feb85a6ce3d929ad019c0d958c039d2b94a1b.lock\n",
            "2025-02-02 22:37:45,271 - filelock - DEBUG - Lock 1346538009616 released on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\e1ff18884359fe8beb795a5f414feb85a6ce3d929ad019c0d958c039d2b94a1b.lock\n",
            "2025-02-02 22:37:45,351 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /distilbert/distilgpt2/resolve/main/generation_config.json HTTP/1.1\" 200 0\n",
            "2025-02-02 22:37:45,352 - filelock - DEBUG - Attempting to acquire lock 1345711053264 on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\057e43033439e068b325f32af95dde9efc9552ae.lock\n",
            "2025-02-02 22:37:45,353 - filelock - DEBUG - Lock 1345711053264 acquired on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\057e43033439e068b325f32af95dde9efc9552ae.lock\n",
            "2025-02-02 22:37:45,412 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"GET /distilbert/distilgpt2/resolve/main/generation_config.json HTTP/1.1\" 200 124\n",
            "2025-02-02 22:37:45,413 - filelock - DEBUG - Attempting to release lock 1345711053264 on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\057e43033439e068b325f32af95dde9efc9552ae.lock\n",
            "2025-02-02 22:37:45,414 - filelock - DEBUG - Lock 1345711053264 released on C:\\Users\\user\\.cache\\huggingface\\hub\\.locks\\models--distilbert--distilgpt2\\057e43033439e068b325f32af95dde9efc9552ae.lock\n",
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_25992\\3927402891.py:117: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=hp[\"bf16\"])\n",
            "Training:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 199\u001b[0m\n\u001b[0;32m    196\u001b[0m     train_model(model, train_loader, val_loader, optimizer, hp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m], device)\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 199\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[6], line 196\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    193\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mhp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[6], line 121\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, optimizer, epochs, device)\u001b[0m\n\u001b[0;32m    119\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    120\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m--> 121\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Move data to target device\u001b[39;49;00m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbf16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
            "Cell \u001b[1;32mIn[6], line 93\u001b[0m, in \u001b[0;36mTextDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Create a prompt similar to your style\u001b[39;00m\n\u001b[0;32m     92\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 93\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     99\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# For causal LM training, labels are identical to input_ids\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: encoding\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: encoding\u001b[38;5;241m.\u001b[39mattention_mask\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: encoding\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    105\u001b[0m }\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2868\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2866\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2867\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2868\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2870\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2978\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m   2956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m   2957\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   2958\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2975\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2976\u001b[0m     )\n\u001b[0;32m   2977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2981\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2995\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2996\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2997\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2998\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2999\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3045\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3024\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;124;03mTokenize and prepare for the model a sequence or a pair of sequences.\u001b[39;00m\n\u001b[0;32m   3026\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3041\u001b[0m \u001b[38;5;124;03m        method).\u001b[39;00m\n\u001b[0;32m   3042\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3044\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m-> 3045\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_padding_truncation_strategies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3051\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3052\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3054\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_plus(\n\u001b[0;32m   3055\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   3056\u001b[0m     text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3074\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3075\u001b[0m )\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\cuda\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2770\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._get_padding_truncation_strategies\u001b[1;34m(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2768\u001b[0m \u001b[38;5;66;03m# Test if we have a padding token\u001b[39;00m\n\u001b[0;32m   2769\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding_strategy \u001b[38;5;241m!=\u001b[39m PaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 2770\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2771\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking to pad but the tokenizer does not have a padding token. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2772\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2773\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor add a new pad token via `tokenizer.add_special_tokens(\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpad_token\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[PAD]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m})`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2774\u001b[0m     )\n\u001b[0;32m   2776\u001b[0m \u001b[38;5;66;03m# Check that we will truncate to a multiple of pad_to_multiple_of if both are provided\u001b[39;00m\n\u001b[0;32m   2777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2778\u001b[0m     truncation_strategy \u001b[38;5;241m!=\u001b[39m TruncationStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_TRUNCATE\n\u001b[0;32m   2779\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m padding_strategy \u001b[38;5;241m!=\u001b[39m PaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2782\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (max_length \u001b[38;5;241m%\u001b[39m pad_to_multiple_of \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2783\u001b[0m ):\n",
            "\u001b[1;31mValueError\u001b[0m: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."
          ]
        }
      ],
      "source": [
        "import logging\n",
        "from pathlib import Path\n",
        "import random\n",
        "import requests\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set or adjust your hyperparameters and amp/cpu override\n",
        "hp = {\n",
        "    \"n_samples\": 5000,\n",
        "    \"test_size\": 0.2,\n",
        "    \"learning_rate\": 0.025,\n",
        "    \"noise\": 0.03,\n",
        "    \"epochs\": 3000,\n",
        "    \"input_features\": 2,\n",
        "    \"output_features\": 1,\n",
        "    \"hidden_units\": 24,\n",
        "    \"random_seed\": 42,\n",
        "    \"randomize_seed\": True,\n",
        "    \"cpu_only\": False,\n",
        "}\n",
        "# Logging configuration\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Randomize seed if set to True\n",
        "if hp['randomize_seed']:\n",
        "    hp['random_seed'] = random.randint(0, 1000000000)\n",
        "logging.info(f\"Seed set to: {hp['random_seed']}\")   \n",
        "\n",
        "def get_device():\n",
        "    \"\"\"\n",
        "    This will check for an Intel XPU device and return it if available, otherwise it will return cpu.\n",
        "\n",
        "    Returns the torch device to use.\n",
        "    \"\"\"\n",
        "    if hp['cpu_only'] == False:\n",
        "        #device = \"xpu\" if torch.xpu.is_available() else \"cpu\"\n",
        "        if torch.xpu.is_available():\n",
        "            device = \"xpu\"\n",
        "        elif torch.cuda.is_available():\n",
        "            device = \"cuda\"\n",
        "        else:\n",
        "            device = \"cpu\"\n",
        "\n",
        "        logging.info(f\"Using device: {device}\")\n",
        "        return device\n",
        "    else:\n",
        "        logging.info(\"Using CPU only\")\n",
        "        return \"cpu\"\n",
        "\n",
        "# Basic Classification Model with ReLU activations\n",
        "class ClassificationModel(nn.Module):\n",
        "    def __init__(self, input_features = 2, output_features = 1, hidden_units = 8):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear_layer_stack = nn.Sequential(\n",
        "            nn.Linear(in_features = input_features, out_features = hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features = hidden_units, out_features = hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features = hidden_units, out_features = hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features = hidden_units, out_features = hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features = hidden_units, out_features = output_features),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "\n",
        "        return self.linear_layer_stack(x)\n",
        "\n",
        "def generate_data(samples, noise, seed, size):\n",
        "    \"\"\"\n",
        "    This function generates a dataset using sklearn's make_circles function.\n",
        "\n",
        "    samples: int, number of samples to generate\n",
        "    noise: float, standard deviation of Gaussian noise added to the data\n",
        "    seed: int, random seed for reproducibility\n",
        "    size: float, size of the test set\n",
        "\n",
        "    Returns the train and test sets as tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate the dataset\n",
        "    X, y = make_circles(samples, noise=noise, random_state=seed)\n",
        "\n",
        "    # Plot the data\n",
        "    plt.scatter(x = X[:, 0], y = X[:, 1], c = y, cmap = plt.cm.RdYlBu)\n",
        "\n",
        "    # Turn data into tensors\n",
        "    X = torch.from_numpy(X).type(torch.float)\n",
        "    y = torch.from_numpy(y).type(torch.float)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=size, random_state=seed)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Calculate accuracy out of 100 examples\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc\n",
        "\n",
        "def import_helper_func():\n",
        "    if Path(\"helper_functions.py\").is_file():\n",
        "        print(\"File exists, skipping download\")\n",
        "    else:\n",
        "        print(\"Downloading\")\n",
        "        request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "        with open(\"helper_functions.py\", \"wb\") as f:\n",
        "            f.write(request.content)\n",
        "\n",
        "    from helper_functions import plot_predictions, plot_decision_boundary\n",
        "\n",
        "def set_seed(seed=hp['random_seed'], device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    if device == \"xpu\":\n",
        "        torch.xpu.manual_seed(seed)\n",
        "    elif device == \"cuda\":\n",
        "        torch.cuda.manual_seed(seed)\n",
        "    logging.info(f\"Seed has been set: {seed}\")\n",
        "\n",
        "def move_to_device(X_train, y_train, X_test, y_test, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Moves data to the target device.\n",
        "    \"\"\"\n",
        "    X_train = X_train.to(device)\n",
        "    y_train = y_train.to(device)\n",
        "    X_test = X_test.to(device)\n",
        "    y_test = y_test.to(device)\n",
        "    logging.info(f\"X_train device: {X_train.device}, y_train device: {y_train.device}\")\n",
        "    logging.info(f\"X_test device: {X_test.device}, y_test device: {y_test.device}\")\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def train_test_model(model, X_train, y_train, X_test, y_test, loss_fn, optimizer, epochs, device=\"cpu\", scaler=None):\n",
        "    \"\"\"\n",
        "    Train and test a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): A PyTorch model.\n",
        "        X_train (torch.Tensor): Training data (features).\n",
        "        y_train (torch.Tensor): Training labels.\n",
        "        X_test (torch.Tensor): Testing data (features).\n",
        "        y_test (torch.Tensor): Testing labels.\n",
        "        loss_fn (torch.nn.Module): An instance of a PyTorch loss function.\n",
        "        optimizer (torch.optim.Optimizer): An instance of a PyTorch optimizer.\n",
        "        epochs (int): Number of epochs to train the model for.\n",
        "        device (str): The target device to run the model on.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Training loss, testing loss\n",
        "    \"\"\"\n",
        "    for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
        "        model.train()\n",
        "\n",
        "        if device != \"cpu\":\n",
        "            with torch.amp.autocast(device):\n",
        "\n",
        "                y_logits = model(X_train).squeeze()\n",
        "                y_pred = torch.round(torch.sigmoid(y_logits))\n",
        "                loss = loss_fn(y_logits, y_train)\n",
        "                acc = accuracy_fn(y_true = y_train, y_pred = y_pred)\n",
        "                optimizer.zero_grad()\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "        else:\n",
        "            y_logits = model(X_train).squeeze()\n",
        "            y_pred = torch.round(torch.sigmoid(y_logits))\n",
        "            loss = loss_fn(y_logits, y_train)\n",
        "            acc = accuracy_fn(y_true = y_train, y_pred = y_pred)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        with torch.inference_mode():\n",
        "\n",
        "            if device != \"cpu\":\n",
        "                with torch.amp.autocast(device):\n",
        "                    test_logits = model(X_test).squeeze()\n",
        "                    test_pred = torch.round(torch.sigmoid(test_logits))\n",
        "\n",
        "            else:\n",
        "                test_logits = model(X_test).squeeze()\n",
        "                test_pred = torch.round(torch.sigmoid(test_logits))\n",
        "                \n",
        "            test_loss = loss_fn(test_logits, y_test)\n",
        "            test_acc = accuracy_fn(y_true = y_test, y_pred = test_pred)\n",
        "\n",
        "    logging.info(f\"Epoch: {epoch} | Loss: {loss:.5f} | Acc: {acc:.2f}% | Test Loss: {test_loss:.5f} | Test Acc: {test_acc:.2f}% | Device: {device}\")\n",
        "\n",
        "# Download helper func from learn pytorch repo if its not downlaoded\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "    print(\"File exists, skipping download\")\n",
        "else:\n",
        "    print(\"Downloading\")\n",
        "    request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "    with open(\"helper_functions.py\", \"wb\") as f:\n",
        "        f.write(request.content)\n",
        "\n",
        "# Then import the file\n",
        "from helper_functions import plot_predictions, plot_decision_boundary\n",
        "\n",
        "# Main function to run training, testing, saving of the model\n",
        "def main():\n",
        "\n",
        "    # Set the device\n",
        "    device = get_device()\n",
        "\n",
        "    # Download helper functions\n",
        "    import_helper_func()\n",
        "\n",
        "    # Call the function to generate the data\n",
        "    X_train, X_test, y_train, y_test = generate_data(samples=hp['n_samples'], noise=hp['noise'], seed=hp['random_seed'], size=hp['test_size'])\n",
        "\n",
        "    # Set with hyperparameters    \n",
        "    model_0 = ClassificationModel(input_features=hp['input_features'], output_features=hp['output_features'], hidden_units=hp['hidden_units']).to(device)\n",
        "\n",
        "    # Make predictions\n",
        "    with torch.inference_mode():\n",
        "        untrained_preds = model_0(X_test.to(device)) # pass test data to model/device\n",
        "\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.SGD(params=model_0.parameters(), lr=hp['learning_rate'])\n",
        "\n",
        "    # View first 5 outputs of the forweard pass on the test data\n",
        "    model_0.eval() # Use training mode when making predictions\n",
        "    with torch.inference_mode(): # Use inference mode when making predictions\n",
        "        y_logits = model_0(X_test.to(device))[:5]\n",
        "\n",
        "    y_pred_probs = torch.sigmoid(y_logits)\n",
        "\n",
        "    ##### Find the predicted labels\n",
        "    # We got raw logits, then turned them into pred probs, now we need pred labels\n",
        "    y_preds = torch.round(y_pred_probs) # predicted labels\n",
        "\n",
        "    # In Full (logits -> pred probs -> pred labels)\n",
        "    y_pred_labels = torch.round(torch.sigmoid(model_0(X_test.to(device))[:5]))\n",
        "\n",
        "    # Get rid of extra dimension\n",
        "    y_preds.squeeze()\n",
        "\n",
        "    set_seed(hp['random_seed'], device)\n",
        "\n",
        "    X_train, y_train, X_test, y_test = move_to_device(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, device=device)\n",
        "\n",
        "    if hp['cpu_only'] == False:\n",
        "        scaler = torch.amp.GradScaler(device)\n",
        "        train_test_model(model_0, X_train, y_train, X_test, y_test, loss_fn, optimizer, hp['epochs'], device, scaler)\n",
        "    else:\n",
        "        train_test_model(model_0, X_train, y_train, X_test, y_test, loss_fn, optimizer, hp['epochs'], device)\n",
        "\n",
        "    # Plot decision boundary of the model\n",
        "    plt.figure(figsize = (12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Train\")\n",
        "    plot_decision_boundary(model_0, X_train, y_train)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Test\")\n",
        "    plot_decision_boundary(model_0, X_test, y_test)\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
