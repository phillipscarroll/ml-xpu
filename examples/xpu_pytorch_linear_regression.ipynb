{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7mWFNse-pzE"
      },
      "source": [
        "# Train And Test - Regression XPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcLiQBnz-pzH"
      },
      "source": [
        "## Linear Regression\n",
        "\n",
        "- Imports\n",
        "  - standard libs\n",
        "  - 3rd party libs\n",
        "  - alpabetical or logical grouping\n",
        "- Set random seed\n",
        "- Config and Hyperparams\n",
        "- Dataset and Dataloader\n",
        "- Model definition/class\n",
        "- Helper functions (training, eval, visualization)\n",
        "- Then main code\n",
        "\n",
        "Note: You can flip torch.amp on and off to test on XPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.amp import GradScaler, autocast\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set or adjust your hyperparameters and amp/cpu override\n",
        "hp = {\n",
        "    \"start\": 0,\n",
        "    \"end\": 1,\n",
        "    \"step\": 0.0002,\n",
        "    \"weight\": 0.7,\n",
        "    \"bias\": 0.3,\n",
        "    \"learning_rate\": 0.005,\n",
        "    \"epochs\": 1500,\n",
        "    \"random_seed\": 42,\n",
        "    \"randomize_seed\": True,\n",
        "    \"cpu_only\": False,\n",
        "}\n",
        "\n",
        "# Logging configuration\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Randomize seed if set to True\n",
        "if hp['randomize_seed']:\n",
        "    hp['random_seed'] = random.randint(0, 1000000000)\n",
        "logging.info(f\"Seed set to: {hp['random_seed']}\")   \n",
        "\n",
        "def get_device(device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    This will check for an Intel XPU device and return it if available, otherwise it will return cpu.\n",
        "\n",
        "    Returns the torch device to use.\n",
        "    \"\"\"\n",
        "    if hp['cpu_only'] == False:\n",
        "        #device = \"xpu\" if torch.xpu.is_available() else \"cpu\"\n",
        "        if torch.xpu.is_available():\n",
        "            device = \"xpu\"\n",
        "        elif torch.cuda.is_available():\n",
        "            device = \"cuda\"\n",
        "        else:\n",
        "            device = \"cpu\"\n",
        "\n",
        "        logging.info(f\"Using device: {device}\")\n",
        "        return device\n",
        "    else:\n",
        "        logging.info(\"Using CPU only\")\n",
        "        return \"cpu\"\n",
        "\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear_layer = nn.Linear(in_features=1, \n",
        "                                      out_features=1)\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.linear_layer(x)\n",
        "\n",
        "# Generate dataset and return the training and test data\n",
        "def generate_dataset(start=0, end=1, step=0.0002, weight=0.7, bias=0.3):\n",
        "    \"\"\"\n",
        "    Generate a dataset for a sample linear regression problem.\n",
        "\n",
        "    Args:\n",
        "        start (float): The start of the X values.\n",
        "        end (float): The end of the X values.\n",
        "        step (float): The step between X values.\n",
        "        weight (float): The weight of the linear equation.\n",
        "        bias (float): The bias of the linear equation.\n",
        "\n",
        "    Returns:\n",
        "        tuple: X_train, y_train, X_test, y_test\n",
        "    \"\"\"\n",
        "    \n",
        "    X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "    y = weight * X + bias \n",
        "      \n",
        "    train_split = int(0.8 * len(X))\n",
        "    X_train, y_train = X[:train_split], y[:train_split]\n",
        "    X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "# Plotting function to visualize the data\n",
        "def plot_predictions(train_data, train_labels, test_data, test_labels, predictions=None):\n",
        "    \"\"\"\n",
        "    Plots training data, test data and compares predictions.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 7))\n",
        "\n",
        "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "\n",
        "    plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "\n",
        "    if predictions is not None:\n",
        "        plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "    plt.xlabel(\"Input\")\n",
        "    plt.ylabel(\"Output\")\n",
        "    plt.title(\"Predictions vs. Actual Data\")\n",
        "    plt.legend(prop={\"size\": 14});\n",
        "\n",
        "def set_seed(seed=hp['random_seed'], device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    if device == \"xpu\":\n",
        "        torch.xpu.manual_seed(seed)\n",
        "    elif device == \"cuda\":\n",
        "        torch.cuda.manual_seed(seed)\n",
        "    logging.info(f\"Seed has been set: {seed}\")\n",
        "\n",
        "def move_to_device(x, y, X_test, y_test, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Moves data to the target device.\n",
        "    \"\"\"\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    X_test = X_test.to(device)\n",
        "    y_test = y_test.to(device)\n",
        "    logging.info(f\"X_train device: {x.device}, y_train device: {y.device}\")\n",
        "    logging.info(f\"X_test device: {X_test.device}, y_test device: {y_test.device}\")\n",
        "    return x, y, X_test, y_test\n",
        "\n",
        "def train_test_model(model, X_train, y_train, X_test, y_test, loss_fn, optimizer, epochs, device=\"cpu\", scaler=None):\n",
        "    \"\"\"\n",
        "    Train and test a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): A PyTorch model.\n",
        "        X_train (torch.Tensor): Training data (features).\n",
        "        y_train (torch.Tensor): Training labels.\n",
        "        X_test (torch.Tensor): Testing data (features).\n",
        "        y_test (torch.Tensor): Testing labels.\n",
        "        loss_fn (torch.nn.Module): An instance of a PyTorch loss function.\n",
        "        optimizer (torch.optim.Optimizer): An instance of a PyTorch optimizer.\n",
        "        epochs (int): Number of epochs to train the model for.\n",
        "        device (str): The target device to run the model on.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Training loss, testing loss\n",
        "    \"\"\"\n",
        "    for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
        "        model.train()\n",
        "\n",
        "        if device != \"cpu\":\n",
        "            with torch.amp.autocast(device):\n",
        "                y_pred = model(X_train)\n",
        "                loss = loss_fn(y_pred, y_train)\n",
        "                optimizer.zero_grad()\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "        else:\n",
        "            y_pred = model(X_train)\n",
        "            loss = loss_fn(y_pred, y_train)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            if device != \"cpu\":\n",
        "                with torch.amp.autocast(device):\n",
        "                    test_pred = model(X_test)\n",
        "            else:\n",
        "                test_pred = model(X_test)\n",
        "\n",
        "            test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "    accuracy = 100 - test_loss.item()\n",
        "    logging.info(f\"Epochs: {epochs} | Train loss: {loss:.5f} | Test loss: {test_loss:.5f} | Accuracy: {accuracy:.5f}%\")\n",
        "\n",
        "    return loss, test_loss\n",
        "\n",
        "# Main function to run training, testing, saving of the model\n",
        "def main():\n",
        "    device = get_device()\n",
        "\n",
        "    X_train, y_train, X_test, y_test = generate_dataset(start=hp['start'], end=hp['end'], step=hp['step'], weight=hp['weight'], bias=hp['bias'])\n",
        "\n",
        "    plot_predictions(X_train.cpu(), y_train.cpu(), X_test.cpu(), y_test.cpu())\n",
        "\n",
        "    logging.info(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "    logging.info(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
        "\n",
        "    set_seed(hp['random_seed'], device)\n",
        "\n",
        "    # This should instantiate the model and move it to the GPU\n",
        "    model_0 = LinearRegressionModel()\n",
        "    model_0.to(device)\n",
        "\n",
        "    loss_fn = nn.L1Loss()\n",
        "    optimizer = torch.optim.SGD(params=model_0.parameters(), lr=hp['learning_rate'])\n",
        "\n",
        "    set_seed(hp['random_seed'])\n",
        "\n",
        "    X_train, y_train, X_test, y_test = move_to_device(X_train, y_train, X_test, y_test, device)\n",
        "\n",
        "    if hp['cpu_only'] == False:\n",
        "        scaler = torch.amp.GradScaler(device)\n",
        "        train_test_model(model=model_0, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, loss_fn=loss_fn, optimizer=optimizer, epochs=hp['epochs'], device=device, scaler=scaler)\n",
        "    else:\n",
        "        train_test_model(model=model_0, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, loss_fn=loss_fn, optimizer=optimizer, epochs=hp['epochs'], device=device)\n",
        "\n",
        "    # Turn on evaluation mode so we don't update the model weights\n",
        "    model_0.eval()\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    with torch.inference_mode():\n",
        "        y_preds = model_0(X_test)\n",
        "\n",
        "    plot_predictions(X_train.cpu(), y_train.cpu(), X_test.cpu(), y_test.cpu(), y_preds.cpu())\n",
        "\n",
        "    # Create models directory if it doesn't exist\n",
        "    MODEL_PATH = Path(\"models\")\n",
        "    MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Create model save path if it doesn't exist\n",
        "    MODEL_NAME = \"LinearRegressionModel_model_0.pth\"\n",
        "    MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "    # Save the model state dict \n",
        "    logging.info(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "    torch.save(obj=model_0.state_dict(), f=MODEL_SAVE_PATH) \n",
        "\n",
        "    # Load the newly saved model\n",
        "    loaded_model_0 = LinearRegressionModel()\n",
        "    loaded_model_0.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "    loaded_model_0.to(device)\n",
        "\n",
        "    # Evaluate loaded model\n",
        "    loaded_model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "        loaded_model_0_preds = loaded_model_0(X_test)\n",
        "    y_preds == loaded_model_0_preds\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
